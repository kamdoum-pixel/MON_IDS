import pandas as pd
import numpy as np
import json # Nouveau: pour parser les logs JSON de Suricata
import datetime
import os
import time # Nouveau: pour les d√©lais d'attente lors de la lecture des logs
import joblib
import yagmail
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt


# D√©finir les noms de colonnes pour le dataset NSL-KDD (reste inchang√©)
feature_names = [
    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',
    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',
    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',
    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',
    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',
    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',
    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',
    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',
    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack_type'
]

# --- VOS FONCTIONS DE CHARGEMENT ET D'ENTRAINEMENT DU MOD√àLE RESTENT ICI ---
# Elles doivent charger vos donn√©es NSL-KDD, entra√Æner le mod√®le,
# et sauvegarder `model`, `preprocessor`, `scaler_X`.

# --- Fonction d'Extraction de Caract√©ristiques √† partir de Eve JSON (voir ci-dessus) ---
# Copiez la fonction `extract_features_from_eve_json` ici.
def extract_features_from_eve_json(eve_event, feature_names):
    """
    Extrait les caract√©ristiques de type NSL-KDD d'un √©v√©nement Eve JSON de Suricata.
    Ceci est une MAPPING SIMPLIFI√âE et doit √™tre adapt√©e/am√©lior√©e !
    Les caract√©ristiques bas√©es sur des agr√©gations (count, rate sur h√¥tes/services)
    ne peuvent pas √™tre d√©riv√©es d'un simple √©v√©nement et sont initialis√©es √† des valeurs par d√©faut.

    :param eve_event: Un dictionnaire repr√©sentant un √©v√©nement Eve JSON.
    :param feature_names: La liste des noms de caract√©ristiques NSL-KDD attendues par le mod√®le.
    :return: Un DataFrame Pandas avec une seule ligne, contenant les caract√©ristiques extraites.
    """
    features = {name: 0 for name in feature_names if name != 'attack_type'} # Initialise toutes les features √† 0

    if eve_event.get("event_type") == "flow":
        flow_data = eve_event

        # duration (calcul√© √† partir de start et end)
        try:
            start_time = datetime.datetime.fromisoformat(flow_data.get("start", "1970-01-01T00:00:00+0000").replace('Z', '+00:00'))
            end_time = datetime.datetime.fromisoformat(flow_data.get("end", "1970-01-01T00:00:00+0000").replace('Z', '+00:00'))
            features['duration'] = (end_time - start_time).total_seconds()
            if features['duration'] < 0: features['duration'] = 0
        except ValueError:
            features['duration'] = 0

        # protocol_type
        features['protocol_type'] = flow_data.get("proto", "unknown").lower()

        # service (souvent li√© au port ou √† l'app_proto)
        app_proto = flow_data.get("app_proto")
        dest_port = flow_data.get("dest_port")
        if app_proto:
            features['service'] = app_proto
        elif dest_port == 80:
            features['service'] = "http"
        elif dest_port == 443:
            features['service'] = "https"
        elif dest_port == 21:
            features['service'] = "ftp"
        elif dest_port == 22:
            features['service'] = "ssh"
        else:
            features['service'] = "other"

        # src_bytes, dst_bytes
        features['src_bytes'] = flow_data.get("bytes_toserver", 0)
        features['dst_bytes'] = flow_data.get("bytes_toclient", 0)

        features['logged_in'] = 0 # Default (needs external context)
        features['flag'] = "SF" # Default, often requires TCP flag analysis

        # Remaining features, mostly aggregations, set to defaults
        features['land'] = 0
        features['wrong_fragment'] = 0
        features['urgent'] = 0
        features['hot'] = 0
        features['num_failed_logins'] = 0
        features['num_compromised'] = 0
        features['root_shell'] = 0
        features['su_attempted'] = 0
        features['num_root'] = 0
        features['num_file_creations'] = 0
        features['num_shells'] = 0
        features['num_access_files'] = 0
        features['num_outbound_cmds'] = 0
        features['is_host_login'] = 0
        features['is_guest_login'] = 0
        
        features['count'] = flow_data.get("pkts_toserver", 0) + flow_data.get("pkts_toclient", 0)
        features['srv_count'] = features['count']
        features['serror_rate'] = 0.0
        features['srv_serror_rate'] = 0.0
        features['rerror_rate'] = 0.0
        features['srv_rerror_rate'] = 0.0

        features['same_srv_rate'] = 1.0
        features['diff_srv_rate'] = 0.0
        features['srv_diff_host_rate'] = 0.0

        features['dst_host_count'] = 1
        features['dst_host_srv_count'] = 1
        features['dst_host_same_srv_rate'] = 1.0
        features['dst_host_diff_srv_rate'] = 0.0
        features['dst_host_same_src_port_rate'] = 0.0
        features['dst_host_srv_diff_host_rate'] = 0.0
        features['dst_host_serror_rate'] = 0.0
        features['dst_host_srv_serror_rate'] = 0.0
        features['dst_host_rerror_rate'] = 0.0
        features['dst_host_srv_rerror_rate'] = 0.0

    elif eve_event.get("event_type") == "alert":
        # Pour les alertes g√©n√©r√©es par les r√®gles Suricata, nous pouvons aussi les consid√©rer.
        # Vous pouvez d√©cider de faire passer ces alertes par le ML ou non.
        # Souvent, si Suricata a d√©j√† alert√©, c'est d√©j√† une menace connue.
        # Mais le ML peut apporter un contexte additionnel.
        pass # Pas de features NSL-KDD directes pour les alertes.
        # Vous pouvez enrichir 'attack_details' pour l'email ici si c'est une alerte Suricata directe.

    feature_row = pd.DataFrame([features])[feature_names[:-1]]
    return feature_row

# --- Fonction d'Envoi d'Alerte par E-mail (reste la m√™me) ---
# Assurez-vous que les variables SENDER_EMAIL, SENDER_PASSWORD, RECEIVER_EMAIL sont configur√©es.
# (Copiez votre fonction send_alert_email ici)
SENDER_EMAIL = "duvalkouatchou@gmail.com"
SENDER_PASSWORD = "bjob gmrs hnhp sbkk"
RECEIVER_EMAIL = ["docteurkamdoum@gmail.com", "autre_destinataire@example.com"]

def send_alert_email(attack_details, current_accuracy=None, current_roc_auc=None, current_classification_rep=None, current_confusion_mat=None):
    # ... votre code de la fonction send_alert_email ...
    try:
        yag = yagmail.SMTP(SENDER_EMAIL, SENDER_PASSWORD)
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        subject = f"üîî ALERTE IDS : Intrusion D√©tect√©e √† {current_time}!"
        
        body = f"""
Cher Administrateur,

Je suis ERATOS votre IDS.

Je viens de d√©tecter une activit√© suspecte sur le r√©seau.

D√©tails de l'incident :
- **Type d'incident :** INTRUSION NON AUTORISE 
- **Heure de l'attaque :** {current_time}
- **D√©tails additionnels :** {attack_details}

Veuillez examiner cette alerte et prendre les mesures n√©cessaires au plus vite, car comme le dit PARKINSON "plus on a de temps pour r√©aliser une t√¢che, plus cette t√¢che prend du temps."

Cordialement,

ERATOS.


"""
        if current_accuracy is not None and current_roc_auc is not None and current_classification_rep is not None and current_confusion_mat is not None:
            body += f"\n\n--- Rapport de Performance du Mod√®le (Global) ---\n"
            body += f"Pr√©cision (Accuracy): {current_accuracy:.4f}\n"
            body += f"Score AUC: {current_roc_auc:.4f}\n"
            body += f"\nRapport de Classification:\n{current_classification_rep}\n"
            body += f"Matrice de Confusion:\n{current_confusion_mat}\n"

        yag.send(to=RECEIVER_EMAIL, subject=subject, contents=body)
        print(f"üö® Alerte par e-mail envoy√©e avec succ√®s √† {RECEIVER_EMAIL}.")
    except Exception as e:
        print(f"‚ùå Erreur lors de l'envoi de l'e-mail d'alerte (Yagmail) : {e}")
        print("V√©rifiez vos identifiants Yagmail (SENDER_EMAIL, SENDER_PASSWORD), l'adresse RECEIVER_EMAIL et votre connexion internet.")


# --- VOS √âTAPES D'ENTRA√éNEMENT ET DE SAUVEGARDE DU MOD√àLE ---
# Cette partie doit s'ex√©cuter une seule fois pour entra√Æner et sauvegarder le mod√®le.
# Assurez-vous que vos fichiers 'ids_random_forest_model.pkl', 'ids_preprocessor.pkl', 'ids_minmax_scaler.pkl'
# existent et sont √† jour.

# --- Chargement des objets n√©cessaires pour la d√©tection en temps r√©el ---
try:
    loaded_model = joblib.load('ids_random_forest_model.pkl')
    loaded_preprocessor = joblib.load('ids_preprocessor.pkl')
    loaded_minmax_scaler = joblib.load('ids_minmax_scaler.pkl')
    print("Mod√®le et pr√©processeurs charg√©s avec succ√®s.")
except FileNotFoundError:
    print("Erreur: Assurez-vous que 'ids_random_forest_model.pkl', 'ids_preprocessor.pkl' et 'ids_minmax_scaler.pkl' existent.")
    print("Ex√©cutez la partie d'entra√Ænement et de sauvegarde du script en premier.")
    exit()

# --- NOUVEAU : Surveillance des Logs Suricata en Temps R√©el ---
SURICATA_EVE_LOG_PATH = "/var/log/suricata/eve.json" # Assurez-vous que ce chemin est correct

print(f"\n--- D√©marrage de la surveillance du fichier de log Suricata : {SURICATA_EVE_LOG_PATH} ---")

# V√©rifier si le fichier de log existe, sinon attendre sa cr√©ation
if not os.path.exists(SURICATA_EVE_LOG_PATH):
    print(f"Le fichier de log {SURICATA_EVE_LOG_PATH} n'existe pas encore. En attente...")
    while not os.path.exists(SURICATA_EVE_LOG_PATH):
        time.sleep(5) # Attendre 5 secondes avant de v√©rifier √† nouveau
    print(f"Fichier de log {SURICATA_EVE_LOG_PATH} d√©tect√©.")

# Boucle principale pour lire le fichier de log en continu
# Utilisation de 'with open' pour une meilleure gestion des ressources
# et 'seek(0, 2)' pour se positionner √† la fin du fichier au d√©marrage.
try:
    with open(SURICATA_EVE_LOG_PATH, 'r') as f:
        # Aller √† la fin du fichier pour ne lire que les nouvelles lignes
        f.seek(0, os.SEEK_END)
        print("Pr√™t √† lire de nouvelles entr√©es de log. CTRL+C pour arr√™ter.")
        
        while True:
            # Lire les nouvelles lignes
            new_line = f.readline()
            if new_line:
                try:
                    eve_event = json.loads(new_line.strip())
                    
                    # Traiter uniquement les √©v√©nements de type 'flow' ou 'alert' pour le ML
                    if eve_event.get("event_type") in ["flow", "alert"]:
                        print(f"\nNouvel √©v√©nement Suricata d√©tect√© ({eve_event.get('event_type')}):")
                        # print(json.dumps(eve_event, indent=2)) # D√©commenter pour voir le JSON brut

                        # Extraire les caract√©ristiques
                        input_df = extract_features_from_eve_json(eve_event, feature_names)

                        # Appliquer le pr√©-traitement
                        # V√©rifier si toutes les colonnes num√©riques/cat√©gorielles du preprocessor sont dans input_df
                        # Si non, cela indique un probl√®me de mapping ou des donn√©es Eve JSON manquantes
                        # Ce cas devrait √™tre g√©r√© plus robustement si extract_features_from_eve_json est simplifi√©.
                        
                        # --- V√©rification des colonnes avant transformation ---
                        # Ceci est important car le preprocessor s'attend √† un certain set de colonnes.
                        missing_cols_num = set(loaded_preprocessor.named_transformers_['num'].feature_names_in_) - set(input_df.columns)
                        missing_cols_cat = set(loaded_preprocessor.named_transformers_['cat'].feature_names_in_) - set(input_df.columns)
                        
                        if missing_cols_num or missing_cols_cat:
                            print(f"AVERTISSEMENT: Caract√©ristiques manquantes dans l'input pour le pr√©processeur:")
                            if missing_cols_num: print(f"Num√©riques: {missing_cols_num}")
                            if missing_cols_cat: print(f"Cat√©gorielles: {missing_cols_cat}")
                            print("Cela peut indiquer un probl√®me avec extract_features_from_eve_json ou le dataset Suricata.")
                            # Vous pouvez choisir de sauter cet √©v√©nement ou de le traiter avec des valeurs par d√©faut.
                            # Pour l'instant, nous continuons, en esp√©rant que le mapping par d√©faut est suffisant.

                        processed_features = loaded_preprocessor.transform(input_df)
                        scaled_features = loaded_minmax_scaler.transform(processed_features)

                        # Faire la pr√©diction
                        prediction = loaded_model.predict(scaled_features)[0]
                        prediction_proba = loaded_model.predict_proba(scaled_features)[0]

                        print(f"Pr√©diction ML: {'Attaque' if prediction == 1 else 'Normal'}")
                        if prediction == 1:
                            # Pr√©cision, AUC, etc. du dernier rapport global.
                            # Pour une alerte en temps r√©el, on ne les a pas pour chaque pr√©diction.
                            # Mais on peut les passer depuis la phase d'entra√Ænement.
                            # Assurez-vous que `accuracy`, `roc_auc`, `classification_rep`, `confusion_mat`
                            # sont des variables globales ou pass√©es d'une mani√®re ou d'une autre.
                            # Pour l'exemple, j'assume que vous les avez sauvegard√©es ou que la fonction
                            # `send_alert_email` peut les g√©rer comme √©tant optionnelles.
                            
                            # Utilisez les m√©triques globales calcul√©es pr√©c√©demment lors de l'entra√Ænement
                            # (Ces variables doivent √™tre accessibles ici, par exemple en tant que globales
                            # ou en passant le r√©sultat de l'entra√Ænement dans une structure).
                            
                            # Exemple pour l'e-mail:
                            details_for_email = f"Source IP: {eve_event.get('src_ip', 'N/A')}, " \
                                                f"Destination IP: {eve_event.get('dest_ip', 'N/A')}, " \
                                                f"Protocole: {eve_event.get('proto', 'N/A')}, " \
                                                f"Service: {eve_event.get('app_proto', eve_event.get('dest_port', 'N/A'))}\n" \
                                                f"Probabilit√© d'attaque: {prediction_proba[1]*100:.2f}%"

                            # Il faut s'assurer que accuracy, roc_auc, classification_rep, confusion_mat
                            # sont d√©finis et accessibles ici. Si vous ex√©cutez le script en une seule fois,
                            # ces variables de l'√©valuation globale le seront.
                            send_alert_email(details_for_email, accuracy, roc_auc, classification_rep, str(confusion_mat))

                        else:
                            print(f"Probabilit√© de normal: {prediction_proba[0]*100:.2f}%")

                except json.JSONDecodeError as e:
                    print(f"Erreur de parsing JSON: {e} dans la ligne: {new_line.strip()}")
                except Exception as e:
                    print(f"Erreur inattendue lors du traitement d'un √©v√©nement: {e}")
            else:
                # Aucune nouvelle ligne, attendre un peu avant de r√©essayer
                time.sleep(0.5) # Attendre 500 ms

except KeyboardInterrupt:
    print("\nArr√™t de la surveillance des logs Suricata.")
except Exception as e:
    print(f"Une erreur grave est survenue lors de la surveillance: {e}")
